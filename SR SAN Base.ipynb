{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmukande-debug/SR-SAN/blob/master/SR%20SAN%20Base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xO1ELZ4lmx0",
        "outputId": "66922d82-b998-4364-f942-1e5c05cc2b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SR-SAN'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 146 (delta 7), reused 0 (delta 0), pack-reused 131\u001b[K\n",
            "Receiving objects: 100% (146/146), 3.05 MiB | 19.29 MiB/s, done.\n",
            "Resolving deltas: 100% (73/73), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tmukande-debug/SR-SAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SR-SAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJuHnrN5l4xB",
        "outputId": "28875811-853b-4ad2-f0a1-a3cad2a6de25"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SR-SAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mega-pytorch"
      ],
      "metadata": {
        "id": "01WysFDNnT4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19568216-7526-442a-c3a0-e494d8eab861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mega-pytorch\n",
            "  Downloading Mega_pytorch-0.0.15-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mega-pytorch) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from mega-pytorch) (1.13.1+cu116)\n",
            "Collecting einops>=0.4\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->mega-pytorch) (4.5.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from scipy->mega-pytorch) (1.22.4)\n",
            "Installing collected packages: einops, mega-pytorch\n",
            "Successfully installed einops-0.6.0 mega-pytorch-0.0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install block_recurrent_transformer_pytorch"
      ],
      "metadata": {
        "id": "U0Na_zxAKrmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d742fd-8648-4935-99f8-64df400d0651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting block_recurrent_transformer_pytorch\n",
            "  Downloading block_recurrent_transformer_pytorch-0.0.18-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from block_recurrent_transformer_pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: einops>=0.4 in /usr/local/lib/python3.8/dist-packages (from block_recurrent_transformer_pytorch) (0.6.0)\n",
            "Collecting beartype\n",
            "  Downloading beartype-0.12.0-py3-none-any.whl (754 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.5/754.5 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->block_recurrent_transformer_pytorch) (4.5.0)\n",
            "Installing collected packages: beartype, block_recurrent_transformer_pytorch\n",
            "Successfully installed beartype-0.12.0 block_recurrent_transformer_pytorch-0.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MNKGWXFmDha",
        "outputId": "08c7a42a-2099-4c0f-da02-b17b36a25bb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batchSize=100, dataset='sample', epoch=12, feedforward=4, hiddenSize=96, l2=1e-05, layer=1, lr=0.001, lr_dc=0.1, lr_dc_step=3, nhead=2, patience=10, valid_portion=0.1, validation=False)\n",
            "-------------------------------------------------------\n",
            "epoch:  0\n",
            "start training:  2023-03-08 17:29:40.097145\n",
            "/content/SR-SAN/model2.py:69: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  A = trans_to_cuda(torch.Tensor(A).float())\n",
            "[0/3751] Loss: 10.5438\n",
            "[751/3751] Loss: 6.0477\n",
            "[1502/3751] Loss: 5.6744\n",
            "[2253/3751] Loss: 4.9783\n",
            "[3004/3751] Loss: 4.3884\n",
            "\tLoss:\t20290.561\n",
            "start predicting:  2023-03-08 17:37:10.093769\n",
            "Best Result:\n",
            "\tRecall@20:\t69.3277\tMMR@20:\t29.0472\tEpoch:\t0,\t0\n",
            "-------------------------------------------------------\n",
            "epoch:  1\n",
            "start training:  2023-03-08 17:37:35.395872\n",
            "[0/3751] Loss: 4.1446\n",
            "[751/3751] Loss: 4.0498\n",
            "[1502/3751] Loss: 4.0374\n",
            "[2253/3751] Loss: 4.1343\n",
            "[3004/3751] Loss: 3.7829\n",
            "\tLoss:\t15906.342\n",
            "start predicting:  2023-03-08 17:45:10.318735\n",
            "Best Result:\n",
            "\tRecall@20:\t70.6633\tMMR@20:\t29.5942\tEpoch:\t1,\t1\n",
            "-------------------------------------------------------\n",
            "epoch:  2\n",
            "start training:  2023-03-08 17:45:35.522494\n",
            "[0/3751] Loss: 3.9138\n",
            "[751/3751] Loss: 4.4298\n",
            "[1502/3751] Loss: 3.7907\n",
            "[2253/3751] Loss: 3.9963\n",
            "[3004/3751] Loss: 3.9727\n",
            "\tLoss:\t15141.499\n",
            "start predicting:  2023-03-08 17:53:06.710925\n",
            "Best Result:\n",
            "\tRecall@20:\t70.9611\tMMR@20:\t30.0552\tEpoch:\t2,\t2\n",
            "-------------------------------------------------------\n",
            "epoch:  3\n",
            "start training:  2023-03-08 17:53:31.406383\n",
            "[0/3751] Loss: 3.9417\n",
            "[751/3751] Loss: 3.6952\n",
            "[1502/3751] Loss: 3.6772\n",
            "[2253/3751] Loss: 3.6002\n",
            "[3004/3751] Loss: 3.4140\n",
            "\tLoss:\t13925.158\n",
            "start predicting:  2023-03-08 18:01:12.294669\n",
            "Best Result:\n",
            "\tRecall@20:\t71.7787\tMMR@20:\t31.3199\tEpoch:\t3,\t3\n",
            "-------------------------------------------------------\n",
            "epoch:  4\n",
            "start training:  2023-03-08 18:01:38.700706\n",
            "[0/3751] Loss: 3.5788\n",
            "[751/3751] Loss: 3.3953\n",
            "[1502/3751] Loss: 3.7724\n",
            "[2253/3751] Loss: 3.5720\n",
            "[3004/3751] Loss: 3.6086\n",
            "\tLoss:\t13697.454\n",
            "start predicting:  2023-03-08 18:09:22.219762\n",
            "Best Result:\n",
            "\tRecall@20:\t71.7787\tMMR@20:\t31.3199\tEpoch:\t3,\t3\n",
            "-------------------------------------------------------\n",
            "epoch:  5\n",
            "start training:  2023-03-08 18:09:48.023833\n",
            "[0/3751] Loss: 3.1962\n",
            "[751/3751] Loss: 3.7486\n",
            "[1502/3751] Loss: 3.6582\n",
            "[2253/3751] Loss: 3.9866\n",
            "[3004/3751] Loss: 3.7967\n",
            "\tLoss:\t13570.734\n",
            "start predicting:  2023-03-08 18:17:32.929600\n",
            "Best Result:\n",
            "\tRecall@20:\t71.7787\tMMR@20:\t31.4451\tEpoch:\t3,\t5\n",
            "-------------------------------------------------------\n",
            "epoch:  6\n",
            "start training:  2023-03-08 18:17:58.697307\n",
            "[0/3751] Loss: 3.7204\n",
            "[751/3751] Loss: 3.8884\n",
            "[1502/3751] Loss: 3.5685\n",
            "[2253/3751] Loss: 3.5894\n",
            "[3004/3751] Loss: 3.5144\n",
            "\tLoss:\t13360.411\n",
            "start predicting:  2023-03-08 18:25:43.104634\n",
            "Best Result:\n",
            "\tRecall@20:\t71.8004\tMMR@20:\t31.4666\tEpoch:\t6,\t6\n",
            "-------------------------------------------------------\n",
            "epoch:  7\n",
            "start training:  2023-03-08 18:26:09.713209\n",
            "[0/3751] Loss: 3.8982\n",
            "[751/3751] Loss: 3.2974\n",
            "[1502/3751] Loss: 3.7950\n",
            "[2253/3751] Loss: 3.1394\n",
            "[3004/3751] Loss: 3.7144\n",
            "\tLoss:\t13345.234\n",
            "start predicting:  2023-03-08 18:33:51.123207\n",
            "Best Result:\n",
            "\tRecall@20:\t71.8004\tMMR@20:\t31.4893\tEpoch:\t6,\t7\n",
            "-------------------------------------------------------\n",
            "epoch:  8\n",
            "start training:  2023-03-08 18:34:16.267223\n",
            "[0/3751] Loss: 3.7196\n",
            "[751/3751] Loss: 3.4543\n",
            "[1502/3751] Loss: 4.0783\n",
            "[2253/3751] Loss: 3.6425\n",
            "[3004/3751] Loss: 3.4264\n",
            "\tLoss:\t13331.660\n",
            "start predicting:  2023-03-08 18:41:44.751152\n",
            "Best Result:\n",
            "\tRecall@20:\t71.8040\tMMR@20:\t31.4923\tEpoch:\t8,\t8\n",
            "-------------------------------------------------------\n",
            "epoch:  9\n",
            "start training:  2023-03-08 18:42:09.428322\n",
            "[0/3751] Loss: 3.3561\n",
            "[751/3751] Loss: 3.4632\n",
            "[1502/3751] Loss: 3.6743\n",
            "[2253/3751] Loss: 3.6514\n",
            "[3004/3751] Loss: 3.7503\n",
            "\tLoss:\t13307.551\n",
            "start predicting:  2023-03-08 18:49:37.480200\n",
            "Best Result:\n",
            "\tRecall@20:\t71.8040\tMMR@20:\t31.5008\tEpoch:\t8,\t9\n",
            "-------------------------------------------------------\n",
            "epoch:  10\n",
            "start training:  2023-03-08 18:50:02.226419\n",
            "[0/3751] Loss: 3.5139\n",
            "[751/3751] Loss: 3.6341\n",
            "[1502/3751] Loss: 3.9739\n",
            "[2253/3751] Loss: 3.3143\n",
            "[3004/3751] Loss: 3.6432\n",
            "\tLoss:\t13308.552\n",
            "start predicting:  2023-03-08 18:57:30.004123\n",
            "Best Result:\n",
            "\tRecall@20:\t71.8040\tMMR@20:\t31.5008\tEpoch:\t8,\t9\n",
            "-------------------------------------------------------\n",
            "epoch:  11\n",
            "start training:  2023-03-08 18:57:54.895048\n",
            "[0/3751] Loss: 3.7155\n",
            "[751/3751] Loss: 3.5034\n",
            "[1502/3751] Loss: 3.7629\n",
            "[2253/3751] Loss: 3.6154\n",
            "[3004/3751] Loss: 2.9931\n",
            "\tLoss:\t13304.865\n",
            "start predicting:  2023-03-08 19:05:24.790164\n",
            "Best Result:\n",
            "\tRecall@20:\t71.8040\tMMR@20:\t31.5008\tEpoch:\t8,\t9\n",
            "-------------------------------------------------------\n",
            "Run time: 5769.480348 s\n"
          ]
        }
      ]
    }
  ]
}