{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqaKUPWK3/wZpSbl3jnsox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmukande-debug/SR-SAN/blob/master/MemComp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xO1ELZ4lmx0",
        "outputId": "1fb75486-a6dd-485d-9620-13fcd6ec196f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SR-SAN'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 109 (delta 52), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (109/109), 3.04 MiB | 3.85 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tmukande-debug/SR-SAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SR-SAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJuHnrN5l4xB",
        "outputId": "788ac18f-4827-4b50-e931-581465c1ecd5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SR-SAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory-efficient-attention-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01WysFDNnT4W",
        "outputId": "0b92e9dd-37c1-4632-f8dc-dae1475990c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting memory-efficient-attention-pytorch\n",
            "  Downloading memory_efficient_attention_pytorch-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from memory-efficient-attention-pytorch) (1.13.1+cu116)\n",
            "Collecting einops>=0.4.1\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->memory-efficient-attention-pytorch) (4.5.0)\n",
            "Installing collected packages: einops, memory-efficient-attention-pytorch\n",
            "Successfully installed einops-0.6.0 memory-efficient-attention-pytorch-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install block-recurrent-transformer-pytorch"
      ],
      "metadata": {
        "id": "U0Na_zxAKrmJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MNKGWXFmDha",
        "outputId": "3f97dae3-27f5-466a-b493-62550d2e7e08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batchSize=100, dataset='sample', epoch=12, feedforward=4, hiddenSize=96, l2=1e-05, layer=1, lr=0.001, lr_dc=0.1, lr_dc_step=3, nhead=2, patience=10, valid_portion=0.1, validation=False)\n",
            "-------------------------------------------------------\n",
            "epoch:  0\n",
            "start training:  2023-02-21 22:27:36.734805\n",
            "/content/SR-SAN/model3.py:92: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  A = trans_to_cuda(torch.Tensor(A).float())\n",
            "[0/3751] Loss: 10.5313\n",
            "[751/3751] Loss: 7.1919\n",
            "[1502/3751] Loss: 7.2781\n",
            "[2253/3751] Loss: 6.1383\n",
            "[3004/3751] Loss: 6.9002\n",
            "\tLoss:\t25873.287\n",
            "start predicting:  2023-02-21 22:34:55.660288\n",
            "Best Result:\n",
            "\tRecall@20:\t39.3575\tMMR@20:\t11.7868\tEpoch:\t0,\t0\n",
            "-------------------------------------------------------\n",
            "epoch:  1\n",
            "start training:  2023-02-21 22:35:19.548791\n",
            "[0/3751] Loss: 5.7046\n",
            "[751/3751] Loss: 6.1136\n",
            "[1502/3751] Loss: 6.0260\n",
            "[2253/3751] Loss: 5.5086\n",
            "[3004/3751] Loss: 5.3993\n",
            "\tLoss:\t21095.818\n",
            "start predicting:  2023-02-21 22:42:33.766400\n",
            "Best Result:\n",
            "\tRecall@20:\t58.8016\tMMR@20:\t22.6707\tEpoch:\t1,\t1\n",
            "-------------------------------------------------------\n",
            "epoch:  2\n",
            "start training:  2023-02-21 22:42:57.292737\n",
            "[0/3751] Loss: 4.6521\n",
            "[751/3751] Loss: 5.5125\n",
            "[1502/3751] Loss: 4.7181\n",
            "[2253/3751] Loss: 4.8148\n",
            "[3004/3751] Loss: 5.4149\n",
            "\tLoss:\t18558.576\n",
            "start predicting:  2023-02-21 22:50:09.733262\n",
            "Best Result:\n",
            "\tRecall@20:\t64.8732\tMMR@20:\t26.2723\tEpoch:\t2,\t2\n",
            "-------------------------------------------------------\n",
            "epoch:  3\n",
            "start training:  2023-02-21 22:50:33.340119\n",
            "[0/3751] Loss: 4.7929\n",
            "[751/3751] Loss: 4.7633\n",
            "[1502/3751] Loss: 4.0854\n",
            "[2253/3751] Loss: 4.5743\n",
            "[3004/3751] Loss: 5.0743\n",
            "\tLoss:\t16853.922\n",
            "start predicting:  2023-02-21 22:57:44.318464\n",
            "Best Result:\n",
            "\tRecall@20:\t67.2051\tMMR@20:\t28.2357\tEpoch:\t3,\t3\n",
            "-------------------------------------------------------\n",
            "epoch:  4\n",
            "start training:  2023-02-21 22:58:06.832608\n",
            "[0/3751] Loss: 3.9117\n",
            "[751/3751] Loss: 4.5249\n",
            "[1502/3751] Loss: 4.6704\n",
            "[2253/3751] Loss: 4.4838\n",
            "[3004/3751] Loss: 4.6320\n",
            "\tLoss:\t16537.398\n",
            "start predicting:  2023-02-21 23:05:17.890276\n",
            "Best Result:\n",
            "\tRecall@20:\t67.5282\tMMR@20:\t28.4490\tEpoch:\t4,\t4\n",
            "-------------------------------------------------------\n",
            "epoch:  5\n",
            "start training:  2023-02-21 23:05:41.355613\n",
            "[0/3751] Loss: 4.6774\n",
            "[751/3751] Loss: 3.9468\n",
            "[1502/3751] Loss: 4.0980\n",
            "[2253/3751] Loss: 4.5216\n",
            "[3004/3751] Loss: 4.5368\n",
            "\tLoss:\t16350.386\n",
            "start predicting:  2023-02-21 23:12:52.164839\n",
            "Best Result:\n",
            "\tRecall@20:\t67.7069\tMMR@20:\t28.5600\tEpoch:\t5,\t5\n",
            "-------------------------------------------------------\n",
            "epoch:  6\n",
            "start training:  2023-02-21 23:13:15.659658\n",
            "[0/3751] Loss: 4.4347\n",
            "[751/3751] Loss: 4.3616\n",
            "[1502/3751] Loss: 4.5194\n",
            "[2253/3751] Loss: 4.4759\n",
            "[3004/3751] Loss: 3.7350\n",
            "\tLoss:\t16122.154\n",
            "start predicting:  2023-02-21 23:20:28.605172\n",
            "Best Result:\n",
            "\tRecall@20:\t67.8693\tMMR@20:\t28.7526\tEpoch:\t6,\t6\n",
            "-------------------------------------------------------\n",
            "epoch:  7\n",
            "start training:  2023-02-21 23:20:51.931545\n",
            "[0/3751] Loss: 3.9799\n",
            "[751/3751] Loss: 4.3802\n",
            "[1502/3751] Loss: 4.4917\n",
            "[2253/3751] Loss: 4.4504\n",
            "[3004/3751] Loss: 4.5545\n",
            "\tLoss:\t16098.791\n",
            "start predicting:  2023-02-21 23:28:05.914928\n",
            "Best Result:\n",
            "\tRecall@20:\t67.9126\tMMR@20:\t28.8382\tEpoch:\t7,\t7\n",
            "-------------------------------------------------------\n",
            "epoch:  8\n",
            "start training:  2023-02-21 23:28:29.483473\n",
            "[0/3751] Loss: 4.7171\n",
            "[751/3751] Loss: 4.4861\n",
            "[1502/3751] Loss: 3.6720\n",
            "[2253/3751] Loss: 3.7765\n",
            "[3004/3751] Loss: 3.8620\n",
            "\tLoss:\t16082.181\n",
            "start predicting:  2023-02-21 23:35:40.598485\n",
            "Best Result:\n",
            "\tRecall@20:\t67.9722\tMMR@20:\t28.8487\tEpoch:\t8,\t8\n",
            "-------------------------------------------------------\n",
            "epoch:  9\n",
            "start training:  2023-02-21 23:36:04.092441\n",
            "[0/3751] Loss: 3.9625\n",
            "[751/3751] Loss: 4.4990\n",
            "[1502/3751] Loss: 4.3987\n",
            "[2253/3751] Loss: 4.4809\n",
            "[3004/3751] Loss: 4.1818\n",
            "\tLoss:\t16053.888\n",
            "start predicting:  2023-02-21 23:43:15.464813\n",
            "Best Result:\n",
            "\tRecall@20:\t67.9722\tMMR@20:\t28.8487\tEpoch:\t8,\t8\n",
            "-------------------------------------------------------\n",
            "epoch:  10\n",
            "start training:  2023-02-21 23:43:38.822157\n",
            "[0/3751] Loss: 3.8842\n",
            "[751/3751] Loss: 4.3893\n",
            "[1502/3751] Loss: 3.6305\n",
            "[2253/3751] Loss: 4.2610\n",
            "[3004/3751] Loss: 4.6244\n",
            "\tLoss:\t16051.514\n",
            "start predicting:  2023-02-21 23:50:47.435530\n",
            "Best Result:\n",
            "\tRecall@20:\t67.9722\tMMR@20:\t28.8493\tEpoch:\t8,\t10\n",
            "-------------------------------------------------------\n",
            "epoch:  11\n",
            "start training:  2023-02-21 23:51:10.940579\n",
            "[0/3751] Loss: 4.3038\n",
            "[751/3751] Loss: 5.0240\n",
            "[1502/3751] Loss: 4.2862\n",
            "[2253/3751] Loss: 4.4611\n",
            "[3004/3751] Loss: 4.6091\n",
            "\tLoss:\t16050.818\n",
            "start predicting:  2023-02-21 23:58:21.031256\n",
            "Best Result:\n",
            "\tRecall@20:\t67.9722\tMMR@20:\t28.8522\tEpoch:\t8,\t11\n",
            "-------------------------------------------------------\n",
            "Run time: 5468.974067 s\n"
          ]
        }
      ]
    }
  ]
}